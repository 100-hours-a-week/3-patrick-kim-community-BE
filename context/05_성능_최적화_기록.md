# PetStar 성능 최적화 기록

## 개요
- **목표**: API 응답시간 p95 < 200ms 달성
- **테스트 환경**: k6, 50 VUs, 1분간 부하
- **서버 스펙**: EC2 t3.small (2 vCPU, 2GB RAM), RDS db.t3.micro

---

## 최적화 #1: HikariCP Connection Pool 튜닝

### 문제 발견
- **현상**: 부하 테스트 시 응답 시간이 급격히 증가
- **Grafana 메트릭 분석**:
  - `hikaricp.connections.acquire` 평균 1.79초
  - `hikaricp.connections.pending` 지속적으로 높음
  - 기본 Pool Size: 10개

### 원인 분석
```
50 VUs 동시 요청 → Connection Pool 10개 부족 → Connection 대기 발생
```

### 해결 방법
**application-dev.yml 수정:**
```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 30        # 10 → 30
      minimum-idle: 10
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      pool-name: PetStarHikariCP
```

**Dockerfile JVM 튜닝:**
```dockerfile
ENV JAVA_OPTS="-Xms512m -Xmx1024m -XX:+UseG1GC -XX:MaxGCPauseMillis=200"
```

### 측정 결과

| 메트릭 | Before | After | 개선율 |
|--------|--------|-------|--------|
| Connection 획득 시간 (평균) | 1.79s | 0.19s | **89% 개선** |
| Pool Size | 10 | 30 | 3배 증가 |

### 커밋
- `aec7a0b` - feat: Phase 3 Connection Pool 및 JVM 튜닝

---

## 최적화 #4: DB 인덱스 추가

### 문제 발견 (EXPLAIN 분석)
```sql
EXPLAIN SELECT e.*, p.*, i.*
FROM entry e
JOIN pet p ON e.pet_id = p.pet_id
JOIN image i ON e.image_id = i.image_id
WHERE e.challenge_id = 1
ORDER BY e.vote_count DESC
LIMIT 10;
```

**EXPLAIN 결과 (인덱스 추가 전):**
```
table | type | key                    | rows | Extra
------|------|------------------------|------|---------------
e     | ref  | uk_entry_challenge_pet | 3334 | Using filesort  ← 문제!
p     | eq_ref | PRIMARY              | 1    | NULL
i     | eq_ref | PRIMARY              | 1    | NULL
```

### 원인 분석
- **Using filesort**: ORDER BY vote_count DESC에서 정렬 발생
- 현재 인덱스 `(challenge_id, pet_id)`는 유니크 제약용
- vote_count 정렬에 인덱스 활용 불가 → 메모리/디스크 정렬

### 해결 방법
```sql
-- ORDER BY 최적화를 위한 복합 인덱스
CREATE INDEX idx_entry_challenge_vote ON entry(challenge_id, vote_count DESC);
```

**EXPLAIN 결과 (인덱스 추가 후):**
```
table | type   | key                      | rows | Extra
------|--------|--------------------------|------|-------
e     | ref    | idx_entry_challenge_vote | 3334 | NULL  ← filesort 제거!
p     | eq_ref | PRIMARY                  | 1    | NULL
i     | eq_ref | PRIMARY                  | 1    | NULL
```

### 측정 결과

| 메트릭 | Before (Fetch Join만) | After (+ Index) | 개선율 |
|--------|----------------------|-----------------|--------|
| ranking API p95 | 234ms | 146ms | **38% 개선** |
| ranking API avg | 92ms | 38ms | **59% 개선** |

### 분석
- **filesort 제거**: ORDER BY를 인덱스로 처리
- **인덱스 설계**: WHERE + ORDER BY 컬럼 조합
- **순서 중요**: Pageable, N+1 해결 후 인덱스 적용해야 효과 극대화

### 커밋
- (아래 참조)

---

## 최적화 #2: DB LIMIT 적용 (Pageable)

### 문제 발견
- **현상**: ranking API에서 100K row 전체를 Java로 로드
- **코드 분석**:
```java
// Before: 전체 로드 후 Java에서 limit
List<Entry> entries = entryRepository.findByChallengeIdOrderByVoteCountDesc(challengeId);
return entries.stream().limit(limit)...  // 100K → 10개를 Java에서 처리
```

### 원인 분석
- JPA 쿼리에 LIMIT 없음
- 100K row를 메모리에 로드 → GC 부하 + 네트워크 비용
- Java Stream `.limit()`은 이미 로드된 후 적용

### 해결 방법
**EntryRepository.java:**
```java
// After: DB에서 LIMIT 적용
List<Entry> findByChallengeIdOrderByVoteCountDesc(Long challengeId, Pageable pageable);
```

**ChallengeService.java:**
```java
List<Entry> entries = entryRepository.findByChallengeIdOrderByVoteCountDesc(
    challengeId, PageRequest.of(0, limit));  // DB에서 10개만 조회
```

### 측정 결과

| 메트릭 | Before | After | 개선율 |
|--------|--------|-------|--------|
| ranking API p95 | 4.76s | 884ms | **81% 개선** |
| ranking API avg | 3.43s | 271ms | **92% 개선** |
| throughput | 10.9 req/s | 38.5 req/s | **3.5배 증가** |

### 분석
- **100K → 10 row**: 데이터 전송량 99.99% 감소
- **메모리 사용량**: 대폭 감소 (GC 부하 ↓)
- **핵심**: DB가 잘하는 건 DB에게 맡기기

### 커밋
- (아래 참조)

---

## 최적화 #3: N+1 쿼리 해결 (Fetch Join)

### 문제 발견
- **현상**: ranking API에서 Entry 10개 조회 후 Pet, Image 각각 추가 쿼리 발생
- **쿼리 패턴**:
```sql
-- 1번: Entry 조회
SELECT * FROM entry WHERE challenge_id = ? ORDER BY vote_count DESC LIMIT 10;

-- N번: 각 Entry마다 Pet 조회 (N+1)
SELECT * FROM pet WHERE pet_id = ?;  -- 10번 반복

-- N번: 각 Entry마다 Image 조회 (N+1)
SELECT * FROM image WHERE image_id = ?;  -- 10번 반복
```
- **총 쿼리 수**: 1 + 10 + 10 = **21개 쿼리**

### 원인 분석
- JPA `@ManyToOne(fetch = FetchType.LAZY)` 설정
- Mapper에서 `entry.getPet().getName()` 접근 시 Lazy Loading 발생
- Entry마다 Pet, Image 각각 SELECT 쿼리 실행

### 해결 방법
**EntryRepository.java - Fetch Join 적용:**
```java
@Query("SELECT e FROM Entry e " +
       "JOIN FETCH e.pet " +
       "JOIN FETCH e.image " +
       "WHERE e.challenge.id = :challengeId " +
       "ORDER BY e.voteCount DESC")
List<Entry> findTopEntriesWithFetchJoin(@Param("challengeId") Long challengeId, Pageable pageable);
```

**실행되는 쿼리:**
```sql
-- 단 1번의 쿼리로 Entry + Pet + Image 모두 조회
SELECT e.*, p.*, i.*
FROM entry e
JOIN pet p ON e.pet_id = p.pet_id
JOIN image i ON e.image_id = i.image_id
WHERE e.challenge_id = ?
ORDER BY e.vote_count DESC
LIMIT 10;
```

### 측정 결과

| 메트릭 | Before (Pageable만) | After (+ Fetch Join) | 개선율 |
|--------|---------------------|----------------------|--------|
| ranking API p95 | 884ms | 234ms | **73% 개선** |
| ranking API avg | 271ms | 92ms | **66% 개선** |
| throughput | 38.5 req/s | 44.8 req/s | 16% 증가 |
| 쿼리 수 | 21개 | 1개 | **95% 감소** |

### 분석
- **쿼리 수 감소**: 21개 → 1개 (95% 감소)
- **DB 라운드트립 감소**: 네트워크 지연 대폭 감소
- **핵심**: N+1은 코드 레벨에서 해결해야 함

### 커밋
- (아래 참조)

---

## 최종 결과 요약

### Ranking API 성능 개선 흐름

| 단계 | p95 | avg | 개선율 |
|------|-----|-----|--------|
| Before (최초) | 4.76s | 3.43s | - |
| #2 Pageable 적용 | 884ms | 271ms | **81% ↓** |
| #3 Fetch Join 적용 | 234ms | 92ms | **73% ↓** |
| #4 인덱스 추가 | 146ms | 38ms | **38% ↓** |
| **총 개선율** | **4.76s → 146ms** | **3.43s → 38ms** | **97% 개선** |

### 전체 최적화 요약

| 최적화 | 대상 | 기법 | 효과 |
|--------|------|------|------|
| #1 Connection Pool | HikariCP | Pool Size 10→30 | 획득 시간 89% ↓ |
| #2 Pageable | JPA Query | DB LIMIT 적용 | 데이터량 99.99% ↓ |
| #3 Fetch Join | N+1 쿼리 | JOIN FETCH | 쿼리 수 95% ↓ |
| #4 Index | ORDER BY | 복합 인덱스 | filesort 제거 |

### 핵심 교훈

1. **최적화 순서가 중요하다**
   - Pageable → N+1 → 인덱스 순서로 해야 각 효과 측정 가능
   - 인덱스만 추가해도 100K 로드 문제는 해결 안 됨

2. **EXPLAIN으로 분석 먼저**
   - 감으로 인덱스 추가 X
   - Using filesort, type: ALL 등 문제점 파악 후 해결

3. **DB가 잘하는 건 DB에게**
   - Java `stream().limit()` → DB `LIMIT`
   - Java 정렬 → DB `ORDER BY` + 인덱스

---

## 최적화 #5: Entries API N+1 해결 (QueryDSL Fetch Join)

### 문제 발견
- **현상**: entries API p95 = 298ms
- **코드 분석 (QueryDSL)**:
```java
return queryFactory
    .selectFrom(entry)
    .where(entry.challenge.id.eq(challengeId), ...)
    .orderBy(entry.id.desc())
    .limit(limit)
    .fetch();  // Entry만 조회 → Pet, Image는 N+1
```

### 원인 분석
- QueryDSL 쿼리에서 Entry만 조회
- Mapper에서 `entry.getPet().getName()`, `entry.getImage().getUrl()` 접근 시 N+1
- 쿼리 수: 1 + 10 + 10 = **21개**

### 해결 방법
**EntryRepositoryImpl.java - QueryDSL Fetch Join:**
```java
return queryFactory
    .selectFrom(entry)
    .join(entry.pet).fetchJoin()    // Fetch Join 추가
    .join(entry.image).fetchJoin()  // Fetch Join 추가
    .where(entry.challenge.id.eq(challengeId), ...)
    .orderBy(entry.id.desc())
    .limit(limit)
    .fetch();
```

### 측정 결과

| 메트릭 | Before | After | 개선율 |
|--------|--------|-------|--------|
| entries API p95 | 298ms | 197ms | **34% 개선** |
| 쿼리 수 | 21개 | 1개 | **95% 감소** |

### 커밋
- (아래 참조)