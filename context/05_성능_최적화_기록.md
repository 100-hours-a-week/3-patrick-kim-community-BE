# PetStar 성능 최적화 기록

## 개요
- **목표**: API 응답시간 p95 < 200ms 달성
- **테스트 환경**: k6, 50 VUs, 1분간 부하
- **서버 스펙**: EC2 t3.small (2 vCPU, 2GB RAM), RDS db.t3.micro

---

## 최적화 #1: HikariCP Connection Pool 튜닝

### 문제 발견
- **현상**: 부하 테스트 시 응답 시간이 급격히 증가
- **Grafana 메트릭 분석**:
  - `hikaricp.connections.acquire` 평균 1.79초
  - `hikaricp.connections.pending` 지속적으로 높음
  - 기본 Pool Size: 10개

### 원인 분석
```
50 VUs 동시 요청 → Connection Pool 10개 부족 → Connection 대기 발생
```

### 해결 방법
**application-dev.yml 수정:**
```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 30        # 10 → 30
      minimum-idle: 10
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      pool-name: PetStarHikariCP
```

**Dockerfile JVM 튜닝:**
```dockerfile
ENV JAVA_OPTS="-Xms512m -Xmx1024m -XX:+UseG1GC -XX:MaxGCPauseMillis=200"
```

### 측정 결과

| 메트릭 | Before | After | 개선율 |
|--------|--------|-------|--------|
| Connection 획득 시간 (평균) | 1.79s | 0.19s | **89% 개선** |
| Pool Size | 10 | 30 | 3배 증가 |

### 커밋
- `aec7a0b` - feat: Phase 3 Connection Pool 및 JVM 튜닝

---

## 최적화 #2: Ranking API 인덱스 추가

### 문제 발견
- **현상**: `/api/v1/challenges/{id}/ranking` API p95 = 5.3s
- **쿼리 분석**:
```sql
SELECT * FROM entry
WHERE challenge_id = ?
ORDER BY vote_count DESC;
```

### 원인 분석 (가설)
- `challenge_id`와 `vote_count` 컬럼에 복합 인덱스 없음
- ORDER BY에서 filesort 발생 가능

### 해결 방법
```sql
CREATE INDEX idx_entry_challenge_vote
ON entry(challenge_id, vote_count DESC);
```

### 측정 결과

| 메트릭 | Before | After | 개선율 |
|--------|--------|-------|--------|
| ranking API p95 | 5.3s | 5.06s | **5% 개선** |
| ranking API avg | 3.65s | 3.48s | 5% 개선 |

### 분석
**인덱스만으로는 개선이 미미함.** 이유:
- 인덱스는 ORDER BY 정렬 속도만 개선
- **진짜 병목**: 100K row 전체를 Java 메모리로 로드 후 `.limit(10)` 적용
- DB에서 LIMIT을 적용하지 않으면 인덱스 효과 제한적

### 교훈
> 인덱스 추가 전에 쿼리 자체가 올바른지 먼저 확인해야 함.
> "전체 로드 후 Java limit" 패턴은 인덱스로 해결 불가.

### 커밋
- (다음 최적화와 함께 커밋 예정)

---

## 최적화 #2: DB LIMIT 적용 (Pageable)

### 문제 발견
- **현상**: ranking API에서 100K row 전체를 Java로 로드
- **코드 분석**:
```java
// Before: 전체 로드 후 Java에서 limit
List<Entry> entries = entryRepository.findByChallengeIdOrderByVoteCountDesc(challengeId);
return entries.stream().limit(limit)...  // 100K → 10개를 Java에서 처리
```

### 원인 분석
- JPA 쿼리에 LIMIT 없음
- 100K row를 메모리에 로드 → GC 부하 + 네트워크 비용
- Java Stream `.limit()`은 이미 로드된 후 적용

### 해결 방법
**EntryRepository.java:**
```java
// After: DB에서 LIMIT 적용
List<Entry> findByChallengeIdOrderByVoteCountDesc(Long challengeId, Pageable pageable);
```

**ChallengeService.java:**
```java
List<Entry> entries = entryRepository.findByChallengeIdOrderByVoteCountDesc(
    challengeId, PageRequest.of(0, limit));  // DB에서 10개만 조회
```

### 측정 결과

| 메트릭 | Before | After | 개선율 |
|--------|--------|-------|--------|
| ranking API p95 | 4.76s | 884ms | **81% 개선** |
| ranking API avg | 3.43s | 271ms | **92% 개선** |
| throughput | 10.9 req/s | 38.5 req/s | **3.5배 증가** |

### 분석
- **100K → 10 row**: 데이터 전송량 99.99% 감소
- **메모리 사용량**: 대폭 감소 (GC 부하 ↓)
- **핵심**: DB가 잘하는 건 DB에게 맡기기

### 커밋
- (아래 참조)

---

## 최적화 #4: N+1 쿼리 해결 (Fetch Join)

### 문제 발견
(예정)

---

## 최종 결과 요약

| 최적화 | 대상 | 개선율 |
|--------|------|--------|
| #1 Connection Pool | Connection 획득 시간 | 89% |
| #2 인덱스 추가 | ranking API | (측정 예정) |
| #3 Pageable | 메모리 사용량 | (측정 예정) |
| #4 Fetch Join | N+1 쿼리 | (측정 예정) |